{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f6d50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verf√ºgbar in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 St√ºck</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \n",
       "0  Amberjacks Steel Dartpfeile sind verf√ºgbar in ...  \n",
       "1  üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...  \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...  \n",
       "3  „ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...  \n",
       "4                                    Inhalt: 1 St√ºck  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"products_train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d734ad13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1551057 entries, 0 to 1551056\n",
      "Data columns (total 11 columns):\n",
      " #   Column    Non-Null Count    Dtype  \n",
      "---  ------    --------------    -----  \n",
      " 0   id        1551057 non-null  object \n",
      " 1   locale    1551057 non-null  object \n",
      " 2   title     1551049 non-null  object \n",
      " 3   price     1551057 non-null  float64\n",
      " 4   brand     1531691 non-null  object \n",
      " 5   color     1125432 non-null  object \n",
      " 6   size      917091 non-null   object \n",
      " 7   model     761137 non-null   object \n",
      " 8   material  834382 non-null   object \n",
      " 9   author    73509 non-null    object \n",
      " 10  desc      1424083 non-null  object \n",
      "dtypes: float64(1), object(10)\n",
      "memory usage: 130.2+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6f16bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              price\n",
      "count  1.551057e+06\n",
      "mean   1.806107e+06\n",
      "std    8.302930e+06\n",
      "min    0.000000e+00\n",
      "25%    1.119000e+01\n",
      "50%    2.328000e+01\n",
      "75%    7.990000e+02\n",
      "max    4.000000e+07\n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "432ae592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'locale', 'title', 'price', 'brand', 'color', 'size', 'model',\n",
      "       'material', 'author', 'desc'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "column_names = df.columns\n",
    "print(column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "579e91ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DE' 'JP' 'UK' 'ES' 'FR' 'IT']\n"
     ]
    }
   ],
   "source": [
    "unique_values = df['locale'].unique()\n",
    "print(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11b4a075",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_samples = df[df['locale'] == 'UK'].copy()\n",
    "de_samples = df[df['locale'] == 'DE'].copy()\n",
    "jp_samples = df[df['locale'] == 'JP'].copy()\n",
    "es_samples = df[df['locale'] == 'ES'].copy()\n",
    "fr_samples = df[df['locale'] == 'FR'].copy()\n",
    "it_samples = df[df['locale'] == 'IT'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c26138e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...\n",
       "1         Simply Keto Lower Carb* Schokodrops ohne Zucke...\n",
       "2         Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...\n",
       "3         AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...\n",
       "4             PLAYMOBIL - 70522 - Cavaliere mit grauem Pony\n",
       "                                ...                        \n",
       "518322    FOSHIO 3 St√ºck Professional 9mm Messer Cutterm...\n",
       "518323    Clearblue Schwangerschaftstest, Schnell und Ei...\n",
       "518324    BODA Creative Windlichter, 6 St√ºck mit Henkel,...\n",
       "518325    Katzenkratzbaum, Kratzbaum gro√ü 124 cm hoch, K...\n",
       "518326    goodjinHH Fl√ºssigleder, Leder Reparatur Creme ...\n",
       "Name: title, Length: 518327, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_samples['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b28475",
   "metadata": {},
   "source": [
    "UK_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b054c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc_processed</th>\n",
       "      <th>title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>913336</th>\n",
       "      <td>B087LZNPHS</td>\n",
       "      <td>UK</td>\n",
       "      <td>SOCHOW Sherpa Fleece Throw Blanket, Double-Sid...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>SOCHOW</td>\n",
       "      <td>Teal Green</td>\n",
       "      <td>127cm√ó150cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100% Polyester</td>\n",
       "      <td>NaN</td>\n",
       "      <td>COLOR: The sherpa throw blanket is available i...</td>\n",
       "      <td>[color, :, sherpa, throw, blanket, avail, vari...</td>\n",
       "      <td>[sochow, sherpa, fleec, throw, blanket, ,, dou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913337</th>\n",
       "      <td>B08THFN1KX</td>\n",
       "      <td>UK</td>\n",
       "      <td>Hippowarehouse Personalised Photo Printed Mous...</td>\n",
       "      <td>9.95</td>\n",
       "      <td>Hippowarehouse</td>\n",
       "      <td>White</td>\n",
       "      <td>240mm x 190mm x 60mm</td>\n",
       "      <td>50245-Mat-Perso</td>\n",
       "      <td>Rubber</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Competitively priced</td>\n",
       "      <td>[competit, price]</td>\n",
       "      <td>[hippowarehous, personalis, photo, print, mous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913338</th>\n",
       "      <td>0804185328</td>\n",
       "      <td>UK</td>\n",
       "      <td>500 Easy Recipes for Every Machine, Both Stove...</td>\n",
       "      <td>16.49</td>\n",
       "      <td>Clarkson Potter</td>\n",
       "      <td>White</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Scarbrough, Mark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[500, easi, recip, everi, machin, ,, stovetop,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913339</th>\n",
       "      <td>B09VBKDBW6</td>\n",
       "      <td>UK</td>\n",
       "      <td>TYHJOY Mini Bag Sealer, Handheld Vacuum Heat S...</td>\n",
       "      <td>11.99</td>\n",
       "      <td>TYHJOY</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FBA-sealer-black</td>\n",
       "      <td>Acrylonitrile Butadiene Styrene</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„ÄêAFTER-SALE„ÄëThis handheld food heat sealer sho...</td>\n",
       "      <td>[„Äêafter-sale„Äëthi, handheld, food, heat, sealer...</td>\n",
       "      <td>[tyhjoy, mini, bag, sealer, ,, handheld, vacuu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913340</th>\n",
       "      <td>B096ZW8B49</td>\n",
       "      <td>UK</td>\n",
       "      <td>Lucosobie Steering Wheel Lock - Car Anti-Theft...</td>\n",
       "      <td>26.99</td>\n",
       "      <td>Lucosobie</td>\n",
       "      <td>Black</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Alloy Steel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üîê„Äê Anti-Friction &amp; Customer First„ÄëEach box of ...</td>\n",
       "      <td>[üîê„Äê, anti-frict, &amp;, custom, first„Äëeach, box, p...</td>\n",
       "      <td>[lucosobi, steer, wheel, lock, -, car, anti-th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id locale                                              title  \\\n",
       "913336  B087LZNPHS     UK  SOCHOW Sherpa Fleece Throw Blanket, Double-Sid...   \n",
       "913337  B08THFN1KX     UK  Hippowarehouse Personalised Photo Printed Mous...   \n",
       "913338  0804185328     UK  500 Easy Recipes for Every Machine, Both Stove...   \n",
       "913339  B09VBKDBW6     UK  TYHJOY Mini Bag Sealer, Handheld Vacuum Heat S...   \n",
       "913340  B096ZW8B49     UK  Lucosobie Steering Wheel Lock - Car Anti-Theft...   \n",
       "\n",
       "        price            brand       color                  size  \\\n",
       "913336  24.99           SOCHOW  Teal Green           127cm√ó150cm   \n",
       "913337   9.95   Hippowarehouse       White  240mm x 190mm x 60mm   \n",
       "913338  16.49  Clarkson Potter       White                   NaN   \n",
       "913339  11.99           TYHJOY       Black                   NaN   \n",
       "913340  26.99        Lucosobie       Black                   NaN   \n",
       "\n",
       "                   model                         material            author  \\\n",
       "913336               NaN                   100% Polyester               NaN   \n",
       "913337   50245-Mat-Perso                           Rubber               NaN   \n",
       "913338               NaN                              NaN  Scarbrough, Mark   \n",
       "913339  FBA-sealer-black  Acrylonitrile Butadiene Styrene               NaN   \n",
       "913340               NaN                      Alloy Steel               NaN   \n",
       "\n",
       "                                                     desc  \\\n",
       "913336  COLOR: The sherpa throw blanket is available i...   \n",
       "913337                               Competitively priced   \n",
       "913338                                                NaN   \n",
       "913339  „ÄêAFTER-SALE„ÄëThis handheld food heat sealer sho...   \n",
       "913340  üîê„Äê Anti-Friction & Customer First„ÄëEach box of ...   \n",
       "\n",
       "                                           desc_processed  \\\n",
       "913336  [color, :, sherpa, throw, blanket, avail, vari...   \n",
       "913337                                  [competit, price]   \n",
       "913338                                                 []   \n",
       "913339  [„Äêafter-sale„Äëthi, handheld, food, heat, sealer...   \n",
       "913340  [üîê„Äê, anti-frict, &, custom, first„Äëeach, box, p...   \n",
       "\n",
       "                                          title_processed  \n",
       "913336  [sochow, sherpa, fleec, throw, blanket, ,, dou...  \n",
       "913337  [hippowarehous, personalis, photo, print, mous...  \n",
       "913338  [500, easi, recip, everi, machin, ,, stovetop,...  \n",
       "913339  [tyhjoy, mini, bag, sealer, ,, handheld, vacuu...  \n",
       "913340  [lucosobi, steer, wheel, lock, -, car, anti-th...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Download required resources from NLTK\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Define the preprocessing functions\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove brackets and non-alphabetic characters\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        \n",
    "        # Sentence tokenization\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Word tokenization, Stemming, Lemmatization, and Stop Word Removal\n",
    "        preprocessed_words = []\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            stemmed_words = [stemmer.stem(word) for word in words]\n",
    "            lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "            filtered_words = [word for word in lemmatized_words if word.lower() not in stop_words]\n",
    "            preprocessed_words.extend(filtered_words)\n",
    "\n",
    "        return preprocessed_words\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the text preprocessing pipeline to the 'desc' column\n",
    "uk_samples['desc_processed'] = uk_samples['desc'].apply(lambda x: preprocess(x))\n",
    "uk_samples['title_processed'] = uk_samples['title'].apply(lambda x: preprocess(x))\n",
    "# Print the updated DataFrame\n",
    "uk_samples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dff1f4e",
   "metadata": {},
   "source": [
    "DE_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33d73751",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc_processed</th>\n",
       "      <th>title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B005ZSSN10</td>\n",
       "      <td>DE</td>\n",
       "      <td>RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...</td>\n",
       "      <td>30.95</td>\n",
       "      <td>RED DRAGON</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RDD0089</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Amberjacks Steel Dartpfeile sind verf√ºgbar in ...</td>\n",
       "      <td>[amberjack, steel, dartpfeil, verfugbar, 21g, ...</td>\n",
       "      <td>[red, dragon, amberjack, 3, -, steel, tip, 22,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B08PRYN6LD</td>\n",
       "      <td>DE</td>\n",
       "      <td>Simply Keto Lower Carb* Schokodrops ohne Zucke...</td>\n",
       "      <td>17.90</td>\n",
       "      <td>Simply Keto</td>\n",
       "      <td>NaN</td>\n",
       "      <td>750 g (1er Pack)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...</td>\n",
       "      <td>[üå±, natur, sus, erythrit, -, stell, ohn, schok...</td>\n",
       "      <td>[simply, keto, low, carb, *, schokodrops, ohn,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B09MBZJ48V</td>\n",
       "      <td>DE</td>\n",
       "      <td>Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...</td>\n",
       "      <td>68.89</td>\n",
       "      <td>Sennheiser</td>\n",
       "      <td>Multi-Colour</td>\n",
       "      <td>One size</td>\n",
       "      <td>508377</td>\n",
       "      <td>Kunstleder</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...</td>\n",
       "      <td>[3.5, mm, buchs, -, problemlos, gerat, standar...</td>\n",
       "      <td>[sennheis, 508377, pc, 5.2, chat, ,, stilvoll,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B08ZN6F26S</td>\n",
       "      <td>DE</td>\n",
       "      <td>AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...</td>\n",
       "      <td>18.99</td>\n",
       "      <td>Amy &amp; Benton</td>\n",
       "      <td>Animal Car</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2008B</td>\n",
       "      <td>aufziehauto 1 jahr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...</td>\n",
       "      <td>[„Äêauto, aufziehbar„Äë, :, druck, einfach, leicht...</td>\n",
       "      <td>[amybenton, auto, ab, 1, 2, 3, ahr, -, baby, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B094DGRV7D</td>\n",
       "      <td>DE</td>\n",
       "      <td>PLAYMOBIL - 70522 - Cavaliere mit grauem Pony</td>\n",
       "      <td>7.17</td>\n",
       "      <td>PLAYMOBIL</td>\n",
       "      <td>Nicht Zutreffend.</td>\n",
       "      <td>OneSize</td>\n",
       "      <td>70522</td>\n",
       "      <td>Polypropylen</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Inhalt: 1 St√ºck</td>\n",
       "      <td>[inhalt, :, 1, stuck]</td>\n",
       "      <td>[playmobil, -, 70522, -, cavali, grau, pony]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id locale                                              title  \\\n",
       "0  B005ZSSN10     DE  RED DRAGON Amberjack 3 - Steel Tip 22 Gramm Wo...   \n",
       "1  B08PRYN6LD     DE  Simply Keto Lower Carb* Schokodrops ohne Zucke...   \n",
       "2  B09MBZJ48V     DE  Sennheiser 508377 PC 5.2 Chat, Stilvolles Mult...   \n",
       "3  B08ZN6F26S     DE  AmyBenton Auto ab 1 2 3 ahre - Baby Aufziehbar...   \n",
       "4  B094DGRV7D     DE      PLAYMOBIL - 70522 - Cavaliere mit grauem Pony   \n",
       "\n",
       "   price         brand              color              size    model  \\\n",
       "0  30.95    RED DRAGON                NaN               NaN  RDD0089   \n",
       "1  17.90   Simply Keto                NaN  750 g (1er Pack)      NaN   \n",
       "2  68.89    Sennheiser       Multi-Colour          One size   508377   \n",
       "3  18.99  Amy & Benton         Animal Car               NaN    2008B   \n",
       "4   7.17     PLAYMOBIL  Nicht Zutreffend.           OneSize    70522   \n",
       "\n",
       "             material author  \\\n",
       "0                 NaN    NaN   \n",
       "1                 NaN    NaN   \n",
       "2          Kunstleder    NaN   \n",
       "3  aufziehauto 1 jahr    NaN   \n",
       "4        Polypropylen    NaN   \n",
       "\n",
       "                                                desc  \\\n",
       "0  Amberjacks Steel Dartpfeile sind verf√ºgbar in ...   \n",
       "1  üå± NAT√úRLICHE S√úSSE DURCH ERYTHRIT - Wir stelle...   \n",
       "2  3.5 MM BUCHSE - Kann problemlos an Ger√§te mit ...   \n",
       "3  „ÄêAuto aufziehbar„Äë: Dr√ºcken Sie einfach leicht ...   \n",
       "4                                    Inhalt: 1 St√ºck   \n",
       "\n",
       "                                      desc_processed  \\\n",
       "0  [amberjack, steel, dartpfeil, verfugbar, 21g, ...   \n",
       "1  [üå±, natur, sus, erythrit, -, stell, ohn, schok...   \n",
       "2  [3.5, mm, buchs, -, problemlos, gerat, standar...   \n",
       "3  [„Äêauto, aufziehbar„Äë, :, druck, einfach, leicht...   \n",
       "4                              [inhalt, :, 1, stuck]   \n",
       "\n",
       "                                     title_processed  \n",
       "0  [red, dragon, amberjack, 3, -, steel, tip, 22,...  \n",
       "1  [simply, keto, low, carb, *, schokodrops, ohn,...  \n",
       "2  [sennheis, 508377, pc, 5.2, chat, ,, stilvoll,...  \n",
       "3  [amybenton, auto, ab, 1, 2, 3, ahr, -, baby, a...  \n",
       "4       [playmobil, -, 70522, -, cavali, grau, pony]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Download required resources from NLTK\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# Define the preprocessing functions\n",
    "stemmer = SnowballStemmer('german')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('german'))\n",
    "\n",
    "def preprocess(text):\n",
    "    if isinstance(text, str):\n",
    "        # Convert text to lowercase\n",
    "        text = text.lower()\n",
    "        \n",
    "        # Remove brackets and non-alphabetic characters\n",
    "        cleaned_text = re.sub(r'[^a-zA-Z√§√∂√º√Ñ√ñ√ú√ü\\s]', '', text)\n",
    "        \n",
    "        # Sentence tokenization\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Word tokenization, Stemming, Lemmatization, and Stop Word Removal\n",
    "        preprocessed_words = []\n",
    "        for sentence in sentences:\n",
    "            words = word_tokenize(sentence)\n",
    "            stemmed_words = [stemmer.stem(word) for word in words]\n",
    "            lemmatized_words = [lemmatizer.lemmatize(word) for word in stemmed_words]\n",
    "            filtered_words = [word for word in lemmatized_words if word.lower() not in stop_words]\n",
    "            preprocessed_words.extend(filtered_words)\n",
    "\n",
    "        return preprocessed_words\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "# Apply the text preprocessing pipeline to the 'desc' column for German language\n",
    "de_samples['desc_processed'] = de_samples['desc'].apply(lambda x: preprocess(x))\n",
    "de_samples['title_processed'] = de_samples['title'].apply(lambda x: preprocess(x))\n",
    "# Print the updated DataFrame\n",
    "de_samples.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c0c1b66",
   "metadata": {},
   "source": [
    "JP_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4de9de50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc_processed</th>\n",
       "      <th>title_processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518327</th>\n",
       "      <td>B0BCFTG541</td>\n",
       "      <td>JP</td>\n",
       "      <td>„ÉØ„Çø„Ç∑„Ç¨„É¢„ÉÜ„Éä„Ç§„Éé„Éè„Éâ„Ç¶„Ç´„É≥„Ç¨„Ç®„ÉÜ„É¢„Ç™„Éû„Ç®„É©„Ç¨„ÉØ„É´„Ç§022 („Éá„Ç∏„Çø„É´„Éê„É≥„Ç¨„É≥„Ç¨„É≥„Ç≥„Éü„ÉÉ„ÇØ„Çπ...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>„Çπ„ÇØ„Ç¶„Çß„Ç¢„Éª„Ç®„Éã„ÉÉ„ÇØ„Çπ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Çø„Éã„Ç¨„ÉØ„Éã„Ç≥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518328</th>\n",
       "      <td>B096F11HV9</td>\n",
       "      <td>JP</td>\n",
       "      <td>Apple MacBook Air M1 2020(13„Ç§„É≥„ÉÅAir,8GB RAM,256...</td>\n",
       "      <td>152000.0</td>\n",
       "      <td>Apple Computer</td>\n",
       "      <td>„Çπ„Éö„Éº„Çπ„Ç∞„É¨„Ç§</td>\n",
       "      <td>RAM:8GB/ SSD:256GB/ 8„Ç≥„Ç¢CPU,7„Ç≥„Ç¢GPU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Touch ID : Touch ID„Çª„É≥„Çµ„Éº</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û]</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Ë£úÂä©Ë®òÂè∑,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518329</th>\n",
       "      <td>B0178VYR6Q</td>\n",
       "      <td>JP</td>\n",
       "      <td>„Ç≠„É¶„Éº„Éî„Éº „ÇÑ„Åï„Åó„ÅÑÁåÆÁ´ã „Å™„ÇÅ„Çâ„Åã„Åî„ÅØ„Çì 150g√ó6ÂÄã„ÄêÂå∫ÂàÜ4:„Åã„Åæ„Å™„Åè„Å¶„Çà„ÅÑ„Äë</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>„Ç≠„É¶„Éº„Éî„Éº</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150„Ç∞„É©„É† (x 6)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Ç´„É≠„É™„Éº:79kcal</td>\n",
       "      <td>[ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û]</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢ÂÆπË©û, ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢Áä∂Ë©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®ò...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518330</th>\n",
       "      <td>B09VWM3SCD</td>\n",
       "      <td>JP</td>\n",
       "      <td>Coticam outdoor „É©„É≥„Çø„É≥„Ç∑„Çß„Éº„Éâ LED „É©„Ç§„Éà „É©„É≥„Çø„É≥ „Ç≠„É£„É≥„Éó „Ç¢„Ç¶„Éà...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>Coticam outdoor</td>\n",
       "      <td>„Éñ„É©„ÉÉ„ÇØ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>‚ÄªÂæÆÁ¥∞„Å™„Ç∑„ÉØ„ÄÅ„Çπ„Ç∏„ÄÅËâ≤„É†„É©„Åå„ÅÇ„ÇãÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åî‰∫ÜÊâøÈ°ò„ÅÑ„Åæ„Åô„ÄÇ „Ç¢„ÉÄ„Éó„Çø„ÅÆ‰ªï‰∏ä„Åå„Çä„ÅØ‰∏ÄÂìÅ„Åî...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©ÂãïË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©Ë©û, ÂãïË©û...</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Âêç...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518331</th>\n",
       "      <td>B07KFZPKLV</td>\n",
       "      <td>JP</td>\n",
       "      <td>Colorsroom „Åì„Åü„Å§Â∏ÉÂõ£ Ê≠£ÊñπÂΩ¢ „Ç≥„Çø„ÉÑÂ∏ÉÂõ£ 185√ó185cm „Ç≥„Çø„ÉÑ„Åµ„Å®„Çì Êéõ„Åë...</td>\n",
       "      <td>4970.0</td>\n",
       "      <td>Â∏ÉÂõ£„Å®ÂØùÂÖ∑Â∞ÇÈñÄÂ∫ó„Ç´„É©„Éº„Ç∫</td>\n",
       "      <td>„Éú„Çø„Éã„Ç´„É´ÊüÑ„Éª„Éô„Éº„Ç∏„É•</td>\n",
       "      <td>„Åì„Åü„Å§Â∏ÉÂõ£185√ó185cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Éï„É©„É≥„Éç„É´,„Ç≥„ÉÉ„Éà„É≥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Äê„ÅîÂÆ∂Â∫≠„Åß‰∏∏Ê¥ó„ÅÑ„Åß„Åç„Çã„ÄÅ„ÅÑ„Å§„ÇÇÊ∏ÖÊΩî„Äë„Ç¶„Ç©„ÉÉ„Ç∑„É£„Éñ„É´‰ªïÊßò„Å†„Åã„Çâ„ÄÅÊ±ö„Çå„Å¶„Åó„Åæ„Å£„Å¶„ÇÇ„Åô„Åê„Å´Ê¥ó„Åà„Çã„ÅÆ...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, Êé•È†≠Ëæû, ÂêçË©û, Âä©Ë©û, ÂêçË©û, ÂãïË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑...</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âêç...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                id locale                                              title  \\\n",
       "518327  B0BCFTG541     JP  „ÉØ„Çø„Ç∑„Ç¨„É¢„ÉÜ„Éä„Ç§„Éé„Éè„Éâ„Ç¶„Ç´„É≥„Ç¨„Ç®„ÉÜ„É¢„Ç™„Éû„Ç®„É©„Ç¨„ÉØ„É´„Ç§022 („Éá„Ç∏„Çø„É´„Éê„É≥„Ç¨„É≥„Ç¨„É≥„Ç≥„Éü„ÉÉ„ÇØ„Çπ...   \n",
       "518328  B096F11HV9     JP  Apple MacBook Air M1 2020(13„Ç§„É≥„ÉÅAir,8GB RAM,256...   \n",
       "518329  B0178VYR6Q     JP          „Ç≠„É¶„Éº„Éî„Éº „ÇÑ„Åï„Åó„ÅÑÁåÆÁ´ã „Å™„ÇÅ„Çâ„Åã„Åî„ÅØ„Çì 150g√ó6ÂÄã„ÄêÂå∫ÂàÜ4:„Åã„Åæ„Å™„Åè„Å¶„Çà„ÅÑ„Äë   \n",
       "518330  B09VWM3SCD     JP  Coticam outdoor „É©„É≥„Çø„É≥„Ç∑„Çß„Éº„Éâ LED „É©„Ç§„Éà „É©„É≥„Çø„É≥ „Ç≠„É£„É≥„Éó „Ç¢„Ç¶„Éà...   \n",
       "518331  B07KFZPKLV     JP  Colorsroom „Åì„Åü„Å§Â∏ÉÂõ£ Ê≠£ÊñπÂΩ¢ „Ç≥„Çø„ÉÑÂ∏ÉÂõ£ 185√ó185cm „Ç≥„Çø„ÉÑ„Åµ„Å®„Çì Êéõ„Åë...   \n",
       "\n",
       "           price            brand        color  \\\n",
       "518327     600.0      „Çπ„ÇØ„Ç¶„Çß„Ç¢„Éª„Ç®„Éã„ÉÉ„ÇØ„Çπ          NaN   \n",
       "518328  152000.0   Apple Computer      „Çπ„Éö„Éº„Çπ„Ç∞„É¨„Ç§   \n",
       "518329    1111.0            „Ç≠„É¶„Éº„Éî„Éº          NaN   \n",
       "518330     999.0  Coticam outdoor         „Éñ„É©„ÉÉ„ÇØ   \n",
       "518331    4970.0     Â∏ÉÂõ£„Å®ÂØùÂÖ∑Â∞ÇÈñÄÂ∫ó„Ç´„É©„Éº„Ç∫  „Éú„Çø„Éã„Ç´„É´ÊüÑ„Éª„Éô„Éº„Ç∏„É•   \n",
       "\n",
       "                                     size model    material  author  \\\n",
       "518327                                NaN   NaN         NaN  „Çø„Éã„Ç¨„ÉØ„Éã„Ç≥   \n",
       "518328  RAM:8GB/ SSD:256GB/ 8„Ç≥„Ç¢CPU,7„Ç≥„Ç¢GPU   NaN         NaN     NaN   \n",
       "518329                       150„Ç∞„É©„É† (x 6)   NaN         NaN     NaN   \n",
       "518330                                NaN   NaN         NaN     NaN   \n",
       "518331                     „Åì„Åü„Å§Â∏ÉÂõ£185√ó185cm   NaN  „Éï„É©„É≥„Éç„É´,„Ç≥„ÉÉ„Éà„É≥     NaN   \n",
       "\n",
       "                                                     desc  \\\n",
       "518327                                                NaN   \n",
       "518328                            Touch ID : Touch ID„Çª„É≥„Çµ„Éº   \n",
       "518329                                        „Ç´„É≠„É™„Éº:79kcal   \n",
       "518330  ‚ÄªÂæÆÁ¥∞„Å™„Ç∑„ÉØ„ÄÅ„Çπ„Ç∏„ÄÅËâ≤„É†„É©„Åå„ÅÇ„ÇãÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åî‰∫ÜÊâøÈ°ò„ÅÑ„Åæ„Åô„ÄÇ „Ç¢„ÉÄ„Éó„Çø„ÅÆ‰ªï‰∏ä„Åå„Çä„ÅØ‰∏ÄÂìÅ„Åî...   \n",
       "518331  „Äê„ÅîÂÆ∂Â∫≠„Åß‰∏∏Ê¥ó„ÅÑ„Åß„Åç„Çã„ÄÅ„ÅÑ„Å§„ÇÇÊ∏ÖÊΩî„Äë„Ç¶„Ç©„ÉÉ„Ç∑„É£„Éñ„É´‰ªïÊßò„Å†„Åã„Çâ„ÄÅÊ±ö„Çå„Å¶„Åó„Åæ„Å£„Å¶„ÇÇ„Åô„Åê„Å´Ê¥ó„Åà„Çã„ÅÆ...   \n",
       "\n",
       "                                           desc_processed  \\\n",
       "518327                                                 []   \n",
       "518328         [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û]   \n",
       "518329                                 [ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û]   \n",
       "518330  [Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©ÂãïË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©Ë©û, ÂãïË©û...   \n",
       "518331  [Ë£úÂä©Ë®òÂè∑, Êé•È†≠Ëæû, ÂêçË©û, Âä©Ë©û, ÂêçË©û, ÂãïË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑...   \n",
       "\n",
       "                                          title_processed  \n",
       "518327                       [ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑]  \n",
       "518328  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Ë£úÂä©Ë®òÂè∑,...  \n",
       "518329  [ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢ÂÆπË©û, ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢Áä∂Ë©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®ò...  \n",
       "518330  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Âêç...  \n",
       "518331  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âêç...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sudachipy import tokenizer\n",
    "from sudachipy import dictionary\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "\n",
    "sudachi_tokenizer = dictionary.Dictionary().create()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def preprocess(text):\n",
    "    if isinstance(text, str):\n",
    "    \n",
    "        # Sentence tokenization\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Word tokenization, Lemmatization, and Stop Word Removal\n",
    "        preprocessed_words = []\n",
    "        for sentence in sentences:\n",
    "            words = sudachi_tokenizer.tokenize(sentence)\n",
    "            lemmatized_words = [lemmatizer.lemmatize(word.part_of_speech()[0]) for word in words]\n",
    "            filtered_words = [word for word in lemmatized_words if word.lower() not in stop_words]\n",
    "            preprocessed_words.extend(filtered_words)\n",
    "\n",
    "        return preprocessed_words\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "\n",
    "# Apply the text preprocessing pipeline to the 'desc' column\n",
    "jp_samples['desc_processed'] = jp_samples['desc'].apply(lambda x: preprocess(x))\n",
    "jp_samples['title_processed'] = jp_samples['title'].apply(lambda x: preprocess(x))\n",
    "# Print the updated DataFrame\n",
    "jp_samples.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da39a5e7",
   "metadata": {},
   "source": [
    "UK_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eff84dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Train Word2Vec model on the preprocessed 'desc' data\n",
    "model = Word2Vec(sentences=uk_samples['desc_processed'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to calculate the word embedding vector for a specific product\n",
    "def calculate_product_embedding(title, desc):\n",
    "    # Check if title and desc are string values\n",
    "    if isinstance(title, str) and isinstance(desc, str):\n",
    "        # Calculate the embedding vector for the 'title' and 'desc'\n",
    "        title_embedding = np.zeros(model.vector_size)\n",
    "        desc_embedding = np.zeros(model.vector_size)\n",
    "        num_title_words = 0\n",
    "        num_desc_words = 0\n",
    "\n",
    "        for word in title.split():\n",
    "            if word in model.wv:\n",
    "                title_embedding += model.wv[word]\n",
    "                num_title_words += 1\n",
    "\n",
    "        for word in desc.split():\n",
    "            if word in model.wv:\n",
    "                desc_embedding += model.wv[word]\n",
    "                num_desc_words += 1\n",
    "\n",
    "        if num_title_words > 0 and num_desc_words > 0:\n",
    "            title_embedding /= num_title_words\n",
    "            desc_embedding /= num_desc_words\n",
    "            return np.concatenate((title_embedding, desc_embedding))\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Convert the list of processed titles and descriptions into sentences\n",
    "uk_samples['title_sentence'] = uk_samples['title_processed'].apply(lambda x: ' '.join(x))\n",
    "uk_samples['desc_sentence'] = uk_samples['desc_processed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a new column 'embeddings' in the 'uk_samples' dataframe\n",
    "uk_samples['embeddings'] = uk_samples.apply(lambda row: calculate_product_embedding(row['title_sentence'], row['desc_sentence']), axis=1)\n",
    "\n",
    "# Print the updated dataframe\n",
    "# uk_samples['embeddings'].shape()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b72d5",
   "metadata": {},
   "source": [
    "DE_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9691d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Train Word2Vec model on the preprocessed 'desc' data\n",
    "model = Word2Vec(sentences=de_samples['desc_processed'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to calculate the word embedding vector for a specific product\n",
    "def calculate_product_embedding(title, desc):\n",
    "    # Check if title and desc are string values\n",
    "    if isinstance(title, str) and isinstance(desc, str):\n",
    "        # Calculate the embedding vector for the 'title' and 'desc'\n",
    "        title_embedding = np.zeros(model.vector_size)\n",
    "        desc_embedding = np.zeros(model.vector_size)\n",
    "        num_title_words = 0\n",
    "        num_desc_words = 0\n",
    "\n",
    "        for word in title.split():\n",
    "            if word in model.wv:\n",
    "                title_embedding += model.wv[word]\n",
    "                num_title_words += 1\n",
    "\n",
    "        for word in desc.split():\n",
    "            if word in model.wv:\n",
    "                desc_embedding += model.wv[word]\n",
    "                num_desc_words += 1\n",
    "\n",
    "        if num_title_words > 0 and num_desc_words > 0:\n",
    "            title_embedding /= num_title_words\n",
    "            desc_embedding /= num_desc_words\n",
    "            return np.concatenate((title_embedding, desc_embedding))\n",
    "\n",
    "    return None\n",
    "\n",
    "# Convert the list of processed titles and descriptions into sentences\n",
    "de_samples['title_sentence'] = de_samples['title_processed'].apply(lambda x: ' '.join(x))\n",
    "de_samples['desc_sentence'] = de_samples['desc_processed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a new column 'embeddings' in the 'uk_samples' dataframe\n",
    "de_samples['embeddings'] = de_samples.apply(lambda row: calculate_product_embedding(row['title_sentence'], row['desc_sentence']), axis=1)\n",
    "\n",
    "# Print the updated dataframe\n",
    "# uk_samples['embeddings'].shape()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa3e205",
   "metadata": {},
   "source": [
    "JP_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f64ea325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "\n",
    "# Train Word2Vec model on the preprocessed 'desc' data\n",
    "model = Word2Vec(sentences=jp_samples['desc_processed'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to calculate the word embedding vector for a specific product\n",
    "def calculate_product_embedding(title, desc):\n",
    "    # Check if title and desc are string values\n",
    "    if isinstance(title, str) and isinstance(desc, str):\n",
    "        # Calculate the embedding vector for the 'title' and 'desc'\n",
    "        title_embedding = np.zeros(model.vector_size)\n",
    "        desc_embedding = np.zeros(model.vector_size)\n",
    "        num_title_words = 0\n",
    "        num_desc_words = 0\n",
    "\n",
    "        for word in title.split():\n",
    "            if word in model.wv:\n",
    "                title_embedding += model.wv[word]\n",
    "                num_title_words += 1\n",
    "\n",
    "        for word in desc.split():\n",
    "            if word in model.wv:\n",
    "                desc_embedding += model.wv[word]\n",
    "                num_desc_words += 1\n",
    "\n",
    "        if num_title_words > 0 and num_desc_words > 0:\n",
    "            title_embedding /= num_title_words\n",
    "            desc_embedding /= num_desc_words\n",
    "            return np.concatenate((title_embedding, desc_embedding))\n",
    "\n",
    "    return None\n",
    "\n",
    "# Convert the list of processed titles and descriptions into sentences\n",
    "jp_samples['title_sentence'] = jp_samples['title_processed'].apply(lambda x: ' '.join(x))\n",
    "jp_samples['desc_sentence'] = jp_samples['desc_processed'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Create a new column 'embeddings' in the 'uk_samples' dataframe\n",
    "jp_samples['embeddings'] = jp_samples.apply(lambda row: calculate_product_embedding(row['title_sentence'], row['desc_sentence']), axis=1)\n",
    "\n",
    "# Print the updated dataframe\n",
    "# uk_samples['embeddings'].shape()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c75b4e4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>locale</th>\n",
       "      <th>title</th>\n",
       "      <th>price</th>\n",
       "      <th>brand</th>\n",
       "      <th>color</th>\n",
       "      <th>size</th>\n",
       "      <th>model</th>\n",
       "      <th>material</th>\n",
       "      <th>author</th>\n",
       "      <th>desc</th>\n",
       "      <th>desc_processed</th>\n",
       "      <th>title_processed</th>\n",
       "      <th>title_sentence</th>\n",
       "      <th>desc_sentence</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>518327</th>\n",
       "      <td>B0BCFTG541</td>\n",
       "      <td>JP</td>\n",
       "      <td>„ÉØ„Çø„Ç∑„Ç¨„É¢„ÉÜ„Éä„Ç§„Éé„Éè„Éâ„Ç¶„Ç´„É≥„Ç¨„Ç®„ÉÜ„É¢„Ç™„Éû„Ç®„É©„Ç¨„ÉØ„É´„Ç§022 („Éá„Ç∏„Çø„É´„Éê„É≥„Ç¨„É≥„Ç¨„É≥„Ç≥„Éü„ÉÉ„ÇØ„Çπ...</td>\n",
       "      <td>600.0</td>\n",
       "      <td>„Çπ„ÇØ„Ç¶„Çß„Ç¢„Éª„Ç®„Éã„ÉÉ„ÇØ„Çπ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Çø„Éã„Ç¨„ÉØ„Éã„Ç≥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑]</td>\n",
       "      <td>ÂêçË©û ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ ÂêçË©û Ë£úÂä©Ë®òÂè∑</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518328</th>\n",
       "      <td>B096F11HV9</td>\n",
       "      <td>JP</td>\n",
       "      <td>Apple MacBook Air M1 2020(13„Ç§„É≥„ÉÅAir,8GB RAM,256...</td>\n",
       "      <td>152000.0</td>\n",
       "      <td>Apple Computer</td>\n",
       "      <td>„Çπ„Éö„Éº„Çπ„Ç∞„É¨„Ç§</td>\n",
       "      <td>RAM:8GB/ SSD:256GB/ 8„Ç≥„Ç¢CPU,7„Ç≥„Ç¢GPU</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Touch ID : Touch ID„Çª„É≥„Çµ„Éº</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û]</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Ë£úÂä©Ë®òÂè∑,...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û Ë£úÂä©...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û</td>\n",
       "      <td>[-0.430854856967926, -0.03222300750868661, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518329</th>\n",
       "      <td>B0178VYR6Q</td>\n",
       "      <td>JP</td>\n",
       "      <td>„Ç≠„É¶„Éº„Éî„Éº „ÇÑ„Åï„Åó„ÅÑÁåÆÁ´ã „Å™„ÇÅ„Çâ„Åã„Åî„ÅØ„Çì 150g√ó6ÂÄã„ÄêÂå∫ÂàÜ4:„Åã„Åæ„Å™„Åè„Å¶„Çà„ÅÑ„Äë</td>\n",
       "      <td>1111.0</td>\n",
       "      <td>„Ç≠„É¶„Éº„Éî„Éº</td>\n",
       "      <td>NaN</td>\n",
       "      <td>150„Ç∞„É©„É† (x 6)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Ç´„É≠„É™„Éº:79kcal</td>\n",
       "      <td>[ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û]</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢ÂÆπË©û, ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢Áä∂Ë©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®ò...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂΩ¢ÂÆπË©û ÂêçË©û Á©∫ÁôΩ ÂΩ¢Áä∂Ë©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û Êé•Â∞æËæû Ë£úÂä©...</td>\n",
       "      <td>ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û</td>\n",
       "      <td>[-0.3310650587081909, 0.09188008668239821, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518330</th>\n",
       "      <td>B09VWM3SCD</td>\n",
       "      <td>JP</td>\n",
       "      <td>Coticam outdoor „É©„É≥„Çø„É≥„Ç∑„Çß„Éº„Éâ LED „É©„Ç§„Éà „É©„É≥„Çø„É≥ „Ç≠„É£„É≥„Éó „Ç¢„Ç¶„Éà...</td>\n",
       "      <td>999.0</td>\n",
       "      <td>Coticam outdoor</td>\n",
       "      <td>„Éñ„É©„ÉÉ„ÇØ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>‚ÄªÂæÆÁ¥∞„Å™„Ç∑„ÉØ„ÄÅ„Çπ„Ç∏„ÄÅËâ≤„É†„É©„Åå„ÅÇ„ÇãÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åî‰∫ÜÊâøÈ°ò„ÅÑ„Åæ„Åô„ÄÇ „Ç¢„ÉÄ„Éó„Çø„ÅÆ‰ªï‰∏ä„Åå„Çä„ÅØ‰∏ÄÂìÅ„Åî...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©ÂãïË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©Ë©û, ÂãïË©û...</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Âêç...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ Âêç...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ ÂêçË©û Âä©ÂãïË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û Âä©Ë©û ÂãïË©û ÂêçË©û Âä©Ë©û ÂãïË©û ...</td>\n",
       "      <td>[-0.6355263629685277, 0.15451034741557162, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518331</th>\n",
       "      <td>B07KFZPKLV</td>\n",
       "      <td>JP</td>\n",
       "      <td>Colorsroom „Åì„Åü„Å§Â∏ÉÂõ£ Ê≠£ÊñπÂΩ¢ „Ç≥„Çø„ÉÑÂ∏ÉÂõ£ 185√ó185cm „Ç≥„Çø„ÉÑ„Åµ„Å®„Çì Êéõ„Åë...</td>\n",
       "      <td>4970.0</td>\n",
       "      <td>Â∏ÉÂõ£„Å®ÂØùÂÖ∑Â∞ÇÈñÄÂ∫ó„Ç´„É©„Éº„Ç∫</td>\n",
       "      <td>„Éú„Çø„Éã„Ç´„É´ÊüÑ„Éª„Éô„Éº„Ç∏„É•</td>\n",
       "      <td>„Åì„Åü„Å§Â∏ÉÂõ£185√ó185cm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Éï„É©„É≥„Éç„É´,„Ç≥„ÉÉ„Éà„É≥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Äê„ÅîÂÆ∂Â∫≠„Åß‰∏∏Ê¥ó„ÅÑ„Åß„Åç„Çã„ÄÅ„ÅÑ„Å§„ÇÇÊ∏ÖÊΩî„Äë„Ç¶„Ç©„ÉÉ„Ç∑„É£„Éñ„É´‰ªïÊßò„Å†„Åã„Çâ„ÄÅÊ±ö„Çå„Å¶„Åó„Åæ„Å£„Å¶„ÇÇ„Åô„Åê„Å´Ê¥ó„Åà„Çã„ÅÆ...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, Êé•È†≠Ëæû, ÂêçË©û, Âä©Ë©û, ÂêçË©û, ÂãïË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑...</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âêç...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ Âêç...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ Êé•È†≠Ëæû ÂêçË©û Âä©Ë©û ÂêçË©û ÂãïË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Âä©ÂãïË©û...</td>\n",
       "      <td>[-0.6369290975283604, 0.13606688707154624, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913331</th>\n",
       "      <td>B08DNQ687B</td>\n",
       "      <td>JP</td>\n",
       "      <td>„Äê„ÇØ„Éº„É´„ÉªÂ∏∏Ê∏©ÈÅ∏Êäû„Äë„Å´„Çì„Åò„Çì5ÔΩãÔΩá„ÄÄËæ≤Ëñ¨‰∏ç‰ΩøÁî®„ÉªÂåñÂ≠¶ËÇ•Êñô‰∏ç‰ΩøÁî®„ÄÄ„ÄÄ„Çè„Åë„ÅÇ„Çä„ÄÄË¶èÊ†ºÂ§ñÂìÅ„ÄÄ„ÄÄ‰∫∫ÂèÇ...</td>\n",
       "      <td>2080.0</td>\n",
       "      <td>„Åä„ÇÑ„Åï„ÅÑÊùë</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5„Ç≠„É≠„Ç∞„É©„É† (x 1)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„ÇØ„Éº„É´‰æø„ÅßÁô∫ÈÄÅ„ÄÄÊúàÊõú„Åã„ÇâÂúüÊõú„Åæ„Åß14ÊôÇ„Åæ„Åß„ÅÆ„ÅîÊ≥®Êñá„ÅßÂΩìÊó•Áô∫ÈÄÅ(Âú®Â∫´„Å™„ÅÑÂ†¥Âêà„ÅØÁøåÊó•Áô∫ÈÄÅ)</td>\n",
       "      <td>[ÂΩ¢Áä∂Ë©û, ÂêçË©û, Âä©Ë©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âä©Ë©û, ÂêçË©û, Âä©Ë©û, ÂêçË©û, ÂêçË©û, ...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, ÂΩ¢Áä∂Ë©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ ÂΩ¢Áä∂Ë©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Êé•È†≠Ëæû ÂêçË©û...</td>\n",
       "      <td>ÂΩ¢Áä∂Ë©û ÂêçË©û Âä©Ë©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Âä©Ë©û ÂêçË©û Âä©Ë©û ÂêçË©û ÂêçË©û Âä©Ë©û Âä©Ë©û Êé•È†≠Ëæû ÂêçË©û...</td>\n",
       "      <td>[-0.5243311790098627, 0.1692050838932754, -0.5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913332</th>\n",
       "      <td>B0932DFYZP</td>\n",
       "      <td>JP</td>\n",
       "      <td>Anjuer „Ç¶„Ç©„Éº„É´„Éè„É≥„Ç¨„Éº Â£ÅÂèñ„Çä‰ªò„ÅëÂºè„Ç≥„Éº„Éà„É©„ÉÉ„ÇØ„ÄÄ5ÈÄ£„Éï„ÉÉ„ÇØ Â£ÅÊéõ„Åë„Éï„ÉÉ„ÇØ ÂèéÁ¥çÂÆ∂ÂÖ∑...</td>\n",
       "      <td>1899.0</td>\n",
       "      <td>Anjuer</td>\n",
       "      <td>Êú®Ëâ≤+Èªí</td>\n",
       "      <td>5ÈÄ£„Éï„ÉÉ„ÇØ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Á´π</td>\n",
       "      <td>NaN</td>\n",
       "      <td>‚óèÂèñ„Çä‰ªò„ÅëÁ∞°ÂçòÔºöÁ∞°Âçò„Å´ÁµÑ„ÅøÁ´ã„Å¶„Çâ„Çå„ÄÅ„Åô„Åê‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ„Åä„Åó„ÇÉ„Çå„Å™Ë®≠Ë®à„ÄÅËÄê‰πÖÊÄß„Åå„ÅÇ„Çä„ÄÅÊ∏ÖÊΩîÊÑü„Çí...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂΩ¢Áä∂Ë©û, Ë£úÂä©Ë®òÂè∑, ÂΩ¢Áä∂Ë©û, Âä©ÂãïË©û, ÂãïË©û, Âä©ÂãïË©û, Ë£úÂä©Ë®òÂè∑,...</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂãïË©û, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Âêç...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂãïË©û ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ Âêç...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂΩ¢Áä∂Ë©û Ë£úÂä©Ë®òÂè∑ ÂΩ¢Áä∂Ë©û Âä©ÂãïË©û ÂãïË©û Âä©ÂãïË©û Ë£úÂä©Ë®òÂè∑ ÂâØË©û ÂêçË©û ÂãïË©û ...</td>\n",
       "      <td>[-0.3921291038393974, 0.04545600228011608, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913333</th>\n",
       "      <td>B095HJ7NM4</td>\n",
       "      <td>JP</td>\n",
       "      <td>ÈùôÈõªÊ∞óÈò≤Ê≠¢ „Éñ„É¨„Çπ„É¨„ÉÉ„Éà Áî∑Â•≥ÂÖºÁî® ÈùôÈõªÊ∞óÈô§Âéª„Éñ„É¨„Çπ„É¨„ÉÉ„Éà [„Éë„ÉÅ„ÉÉ„Å®„Åè„Çã ÈùôÈõªÊ∞ó „Çí„Åó„Å£„Åã...</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>PHATHiNG</td>\n",
       "      <td>„Éñ„É´„Éº</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Ç∑„É™„Ç≥„Éº„É≥</td>\n",
       "      <td>NaN</td>\n",
       "      <td>„Äê „Çπ„Çø„Ç§„É™„ÉÉ„Ç∑„É•„Å´ ÈùôÈõªÊ∞óÈò≤Ê≠¢ „Äë Êú¨Ë£ΩÂìÅ„ÅÆÈùôÈõªÊ∞óÈò≤Ê≠¢„Éñ„É¨„Çπ„É¨„ÉÉ„Éà„ÅØ„ÄÅË¶ã„ÅüÁõÆ„ÇÇ„Åä„Åó„ÇÉ„Çå„Åß„ÄÅ...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ, ÂΩ¢Áä∂Ë©û, Âä©ÂãïË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ,...</td>\n",
       "      <td>[ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫...</td>\n",
       "      <td>ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ ÂâØË©û Âä©Ë©û...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ Á©∫ÁôΩ ÂΩ¢Áä∂Ë©û Âä©ÂãïË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ Á©∫ÁôΩ Êé•È†≠Ëæû ÂêçË©û Âä©Ë©û ...</td>\n",
       "      <td>[-0.5518289059400558, 0.11609400767419073, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913334</th>\n",
       "      <td>B07XJ2TFTX</td>\n",
       "      <td>JP</td>\n",
       "      <td>switch lite„Ç´„Éê„Éº „Çπ„Ç§„ÉÉ„ÉÅ„É©„Ç§„Éà „Ç±„Éº„Çπ TPUÁ¥†Êùê ‰∏Ä‰ΩìÂºè ÂÖ®Èù¢‰øùË≠∑ ËÄêË°ùÊíÉ ...</td>\n",
       "      <td>1699.0</td>\n",
       "      <td>CHINFAI</td>\n",
       "      <td>„Éñ„É©„ÉÉ„ÇØ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üéÆ„Äê„Çπ„Çø„É≥„ÉâÊ©üËÉΩ‰ªò„Åç„Äë„Çπ„Çø„É≥„ÉâÊ©üËÉΩ„ÅÇ„ÇäÁâπÊÆä„Éè„É≥„Éâ„É´Ë®≠Ë®à„ÅØ„Ç™„É™„Ç∏„Éä„É´„Åß„ÄÅ„Ç´„Éê„Éº„Çí‰ªò„Åë„Åü„Åæ„Åæsw...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Êé•Â∞æËæû, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, ÂêçË©û, ÂΩ¢Áä∂...</td>\n",
       "      <td>[ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âêç...</td>\n",
       "      <td>ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Êé•Â∞æËæû Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û ÂΩ¢Áä∂Ë©û ÂêçË©û ÂêçË©û Âä©Ë©û...</td>\n",
       "      <td>[-0.518697532645443, 0.07392928710109309, -0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913335</th>\n",
       "      <td>B0BJQ8T2VM</td>\n",
       "      <td>JP</td>\n",
       "      <td>„Äê‰ª§ÂíåÊ¨°‰∏ñ‰ª£Bluetooth „Ç§„É§„Éõ„É≥„ÄëÁû¨ÈñìÊé•Á∂ö „ÉØ„Ç§„É§„É¨„Çπ„Ç§„É§„Éõ„É≥ Bluetooth5...</td>\n",
       "      <td>3580.0</td>\n",
       "      <td>Blulu</td>\n",
       "      <td>„Éõ„ÉØ„Ç§„Éà</td>\n",
       "      <td>NaN</td>\n",
       "      <td>X6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>üéµ‚ú®„ÄêBlulu„ÅÆÂÆåÂÖ®„ÉØ„Ç§„É§„É¨„Çπ„Ç§„É§„Éõ„É≥„ÅåÊñ∞ÁôªÂ†¥ÔºÅÈ´ò„ÅÑÊé•Á∂öÊÄß„Åß„Çπ„Éà„É¨„Çπ„Éï„É™„Éº„Äë2022Âπ¥„Åã„Å§...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Âä©Ë©û, ÂΩ¢Áä∂Ë©û, ÂêçË©û, ÂêçË©û, Âä©Ë©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ...</td>\n",
       "      <td>[Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Âêç...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ...</td>\n",
       "      <td>Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Âä©Ë©û ÂΩ¢Áä∂Ë©û ÂêçË©û ÂêçË©û Âä©Ë©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂΩ¢ÂÆπË©û ÂêçË©û Êé•Â∞æËæû ...</td>\n",
       "      <td>[-0.47958834249843924, 0.020226624678791494, -...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>395009 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id locale                                              title  \\\n",
       "518327  B0BCFTG541     JP  „ÉØ„Çø„Ç∑„Ç¨„É¢„ÉÜ„Éä„Ç§„Éé„Éè„Éâ„Ç¶„Ç´„É≥„Ç¨„Ç®„ÉÜ„É¢„Ç™„Éû„Ç®„É©„Ç¨„ÉØ„É´„Ç§022 („Éá„Ç∏„Çø„É´„Éê„É≥„Ç¨„É≥„Ç¨„É≥„Ç≥„Éü„ÉÉ„ÇØ„Çπ...   \n",
       "518328  B096F11HV9     JP  Apple MacBook Air M1 2020(13„Ç§„É≥„ÉÅAir,8GB RAM,256...   \n",
       "518329  B0178VYR6Q     JP          „Ç≠„É¶„Éº„Éî„Éº „ÇÑ„Åï„Åó„ÅÑÁåÆÁ´ã „Å™„ÇÅ„Çâ„Åã„Åî„ÅØ„Çì 150g√ó6ÂÄã„ÄêÂå∫ÂàÜ4:„Åã„Åæ„Å™„Åè„Å¶„Çà„ÅÑ„Äë   \n",
       "518330  B09VWM3SCD     JP  Coticam outdoor „É©„É≥„Çø„É≥„Ç∑„Çß„Éº„Éâ LED „É©„Ç§„Éà „É©„É≥„Çø„É≥ „Ç≠„É£„É≥„Éó „Ç¢„Ç¶„Éà...   \n",
       "518331  B07KFZPKLV     JP  Colorsroom „Åì„Åü„Å§Â∏ÉÂõ£ Ê≠£ÊñπÂΩ¢ „Ç≥„Çø„ÉÑÂ∏ÉÂõ£ 185√ó185cm „Ç≥„Çø„ÉÑ„Åµ„Å®„Çì Êéõ„Åë...   \n",
       "...            ...    ...                                                ...   \n",
       "913331  B08DNQ687B     JP  „Äê„ÇØ„Éº„É´„ÉªÂ∏∏Ê∏©ÈÅ∏Êäû„Äë„Å´„Çì„Åò„Çì5ÔΩãÔΩá„ÄÄËæ≤Ëñ¨‰∏ç‰ΩøÁî®„ÉªÂåñÂ≠¶ËÇ•Êñô‰∏ç‰ΩøÁî®„ÄÄ„ÄÄ„Çè„Åë„ÅÇ„Çä„ÄÄË¶èÊ†ºÂ§ñÂìÅ„ÄÄ„ÄÄ‰∫∫ÂèÇ...   \n",
       "913332  B0932DFYZP     JP  Anjuer „Ç¶„Ç©„Éº„É´„Éè„É≥„Ç¨„Éº Â£ÅÂèñ„Çä‰ªò„ÅëÂºè„Ç≥„Éº„Éà„É©„ÉÉ„ÇØ„ÄÄ5ÈÄ£„Éï„ÉÉ„ÇØ Â£ÅÊéõ„Åë„Éï„ÉÉ„ÇØ ÂèéÁ¥çÂÆ∂ÂÖ∑...   \n",
       "913333  B095HJ7NM4     JP  ÈùôÈõªÊ∞óÈò≤Ê≠¢ „Éñ„É¨„Çπ„É¨„ÉÉ„Éà Áî∑Â•≥ÂÖºÁî® ÈùôÈõªÊ∞óÈô§Âéª„Éñ„É¨„Çπ„É¨„ÉÉ„Éà [„Éë„ÉÅ„ÉÉ„Å®„Åè„Çã ÈùôÈõªÊ∞ó „Çí„Åó„Å£„Åã...   \n",
       "913334  B07XJ2TFTX     JP  switch lite„Ç´„Éê„Éº „Çπ„Ç§„ÉÉ„ÉÅ„É©„Ç§„Éà „Ç±„Éº„Çπ TPUÁ¥†Êùê ‰∏Ä‰ΩìÂºè ÂÖ®Èù¢‰øùË≠∑ ËÄêË°ùÊíÉ ...   \n",
       "913335  B0BJQ8T2VM     JP  „Äê‰ª§ÂíåÊ¨°‰∏ñ‰ª£Bluetooth „Ç§„É§„Éõ„É≥„ÄëÁû¨ÈñìÊé•Á∂ö „ÉØ„Ç§„É§„É¨„Çπ„Ç§„É§„Éõ„É≥ Bluetooth5...   \n",
       "\n",
       "           price            brand        color  \\\n",
       "518327     600.0      „Çπ„ÇØ„Ç¶„Çß„Ç¢„Éª„Ç®„Éã„ÉÉ„ÇØ„Çπ          NaN   \n",
       "518328  152000.0   Apple Computer      „Çπ„Éö„Éº„Çπ„Ç∞„É¨„Ç§   \n",
       "518329    1111.0            „Ç≠„É¶„Éº„Éî„Éº          NaN   \n",
       "518330     999.0  Coticam outdoor         „Éñ„É©„ÉÉ„ÇØ   \n",
       "518331    4970.0     Â∏ÉÂõ£„Å®ÂØùÂÖ∑Â∞ÇÈñÄÂ∫ó„Ç´„É©„Éº„Ç∫  „Éú„Çø„Éã„Ç´„É´ÊüÑ„Éª„Éô„Éº„Ç∏„É•   \n",
       "...          ...              ...          ...   \n",
       "913331    2080.0            „Åä„ÇÑ„Åï„ÅÑÊùë          NaN   \n",
       "913332    1899.0           Anjuer         Êú®Ëâ≤+Èªí   \n",
       "913333    1280.0         PHATHiNG          „Éñ„É´„Éº   \n",
       "913334    1699.0          CHINFAI         „Éñ„É©„ÉÉ„ÇØ   \n",
       "913335    3580.0            Blulu         „Éõ„ÉØ„Ç§„Éà   \n",
       "\n",
       "                                     size model    material  author  \\\n",
       "518327                                NaN   NaN         NaN  „Çø„Éã„Ç¨„ÉØ„Éã„Ç≥   \n",
       "518328  RAM:8GB/ SSD:256GB/ 8„Ç≥„Ç¢CPU,7„Ç≥„Ç¢GPU   NaN         NaN     NaN   \n",
       "518329                       150„Ç∞„É©„É† (x 6)   NaN         NaN     NaN   \n",
       "518330                                NaN   NaN         NaN     NaN   \n",
       "518331                     „Åì„Åü„Å§Â∏ÉÂõ£185√ó185cm   NaN  „Éï„É©„É≥„Éç„É´,„Ç≥„ÉÉ„Éà„É≥     NaN   \n",
       "...                                   ...   ...         ...     ...   \n",
       "913331                       5„Ç≠„É≠„Ç∞„É©„É† (x 1)   NaN         NaN     NaN   \n",
       "913332                              5ÈÄ£„Éï„ÉÉ„ÇØ   NaN           Á´π     NaN   \n",
       "913333                                NaN   NaN       „Ç∑„É™„Ç≥„Éº„É≥     NaN   \n",
       "913334                                NaN   NaN         NaN     NaN   \n",
       "913335                                NaN    X6         NaN     NaN   \n",
       "\n",
       "                                                     desc  \\\n",
       "518327                                                NaN   \n",
       "518328                            Touch ID : Touch ID„Çª„É≥„Çµ„Éº   \n",
       "518329                                        „Ç´„É≠„É™„Éº:79kcal   \n",
       "518330  ‚ÄªÂæÆÁ¥∞„Å™„Ç∑„ÉØ„ÄÅ„Çπ„Ç∏„ÄÅËâ≤„É†„É©„Åå„ÅÇ„ÇãÂ†¥Âêà„Åå„ÅÇ„Çä„Åæ„Åô„ÄÇ„Åî‰∫ÜÊâøÈ°ò„ÅÑ„Åæ„Åô„ÄÇ „Ç¢„ÉÄ„Éó„Çø„ÅÆ‰ªï‰∏ä„Åå„Çä„ÅØ‰∏ÄÂìÅ„Åî...   \n",
       "518331  „Äê„ÅîÂÆ∂Â∫≠„Åß‰∏∏Ê¥ó„ÅÑ„Åß„Åç„Çã„ÄÅ„ÅÑ„Å§„ÇÇÊ∏ÖÊΩî„Äë„Ç¶„Ç©„ÉÉ„Ç∑„É£„Éñ„É´‰ªïÊßò„Å†„Åã„Çâ„ÄÅÊ±ö„Çå„Å¶„Åó„Åæ„Å£„Å¶„ÇÇ„Åô„Åê„Å´Ê¥ó„Åà„Çã„ÅÆ...   \n",
       "...                                                   ...   \n",
       "913331        „ÇØ„Éº„É´‰æø„ÅßÁô∫ÈÄÅ„ÄÄÊúàÊõú„Åã„ÇâÂúüÊõú„Åæ„Åß14ÊôÇ„Åæ„Åß„ÅÆ„ÅîÊ≥®Êñá„ÅßÂΩìÊó•Áô∫ÈÄÅ(Âú®Â∫´„Å™„ÅÑÂ†¥Âêà„ÅØÁøåÊó•Áô∫ÈÄÅ)   \n",
       "913332  ‚óèÂèñ„Çä‰ªò„ÅëÁ∞°ÂçòÔºöÁ∞°Âçò„Å´ÁµÑ„ÅøÁ´ã„Å¶„Çâ„Çå„ÄÅ„Åô„Åê‰ΩøÁî®„Åß„Åç„Åæ„Åô„ÄÇ„Åä„Åó„ÇÉ„Çå„Å™Ë®≠Ë®à„ÄÅËÄê‰πÖÊÄß„Åå„ÅÇ„Çä„ÄÅÊ∏ÖÊΩîÊÑü„Çí...   \n",
       "913333  „Äê „Çπ„Çø„Ç§„É™„ÉÉ„Ç∑„É•„Å´ ÈùôÈõªÊ∞óÈò≤Ê≠¢ „Äë Êú¨Ë£ΩÂìÅ„ÅÆÈùôÈõªÊ∞óÈò≤Ê≠¢„Éñ„É¨„Çπ„É¨„ÉÉ„Éà„ÅØ„ÄÅË¶ã„ÅüÁõÆ„ÇÇ„Åä„Åó„ÇÉ„Çå„Åß„ÄÅ...   \n",
       "913334  üéÆ„Äê„Çπ„Çø„É≥„ÉâÊ©üËÉΩ‰ªò„Åç„Äë„Çπ„Çø„É≥„ÉâÊ©üËÉΩ„ÅÇ„ÇäÁâπÊÆä„Éè„É≥„Éâ„É´Ë®≠Ë®à„ÅØ„Ç™„É™„Ç∏„Éä„É´„Åß„ÄÅ„Ç´„Éê„Éº„Çí‰ªò„Åë„Åü„Åæ„Åæsw...   \n",
       "913335  üéµ‚ú®„ÄêBlulu„ÅÆÂÆåÂÖ®„ÉØ„Ç§„É§„É¨„Çπ„Ç§„É§„Éõ„É≥„ÅåÊñ∞ÁôªÂ†¥ÔºÅÈ´ò„ÅÑÊé•Á∂öÊÄß„Åß„Çπ„Éà„É¨„Çπ„Éï„É™„Éº„Äë2022Âπ¥„Åã„Å§...   \n",
       "\n",
       "                                           desc_processed  \\\n",
       "518327                                                 []   \n",
       "518328         [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û]   \n",
       "518329                                 [ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û]   \n",
       "518330  [Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©ÂãïË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Âä©Ë©û, ÂãïË©û...   \n",
       "518331  [Ë£úÂä©Ë®òÂè∑, Êé•È†≠Ëæû, ÂêçË©û, Âä©Ë©û, ÂêçË©û, ÂãïË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑...   \n",
       "...                                                   ...   \n",
       "913331  [ÂΩ¢Áä∂Ë©û, ÂêçË©û, Âä©Ë©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âä©Ë©û, ÂêçË©û, Âä©Ë©û, ÂêçË©û, ÂêçË©û, ...   \n",
       "913332  [Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂΩ¢Áä∂Ë©û, Ë£úÂä©Ë®òÂè∑, ÂΩ¢Áä∂Ë©û, Âä©ÂãïË©û, ÂãïË©û, Âä©ÂãïË©û, Ë£úÂä©Ë®òÂè∑,...   \n",
       "913333  [Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ, ÂΩ¢Áä∂Ë©û, Âä©ÂãïË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, Á©∫ÁôΩ,...   \n",
       "913334  [Ë£úÂä©Ë®òÂè∑, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Êé•Â∞æËæû, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, ÂêçË©û, ÂΩ¢Áä∂...   \n",
       "913335  [Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Âä©Ë©û, ÂΩ¢Áä∂Ë©û, ÂêçË©û, ÂêçË©û, Âä©Ë©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ...   \n",
       "\n",
       "                                          title_processed  \\\n",
       "518327                       [ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, Ë£úÂä©Ë®òÂè∑]   \n",
       "518328  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Ë£úÂä©Ë®òÂè∑,...   \n",
       "518329  [ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢ÂÆπË©û, ÂêçË©û, Á©∫ÁôΩ, ÂΩ¢Áä∂Ë©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®ò...   \n",
       "518330  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, Âêç...   \n",
       "518331  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âêç...   \n",
       "...                                                   ...   \n",
       "913331  [Ë£úÂä©Ë®òÂè∑, ÂΩ¢Áä∂Ë©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ...   \n",
       "913332  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂãïË©û, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Âêç...   \n",
       "913333  [ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫...   \n",
       "913334  [ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Âêç...   \n",
       "913335  [Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, ÂêçË©û, Ë£úÂä©Ë®òÂè∑, ÂêçË©û, ÂêçË©û, Á©∫ÁôΩ, Âêç...   \n",
       "\n",
       "                                           title_sentence  \\\n",
       "518327                              ÂêçË©û ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ ÂêçË©û Ë£úÂä©Ë®òÂè∑   \n",
       "518328  ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û Ë£úÂä©...   \n",
       "518329  ÂêçË©û Á©∫ÁôΩ ÂΩ¢ÂÆπË©û ÂêçË©û Á©∫ÁôΩ ÂΩ¢Áä∂Ë©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û Êé•Â∞æËæû Ë£úÂä©...   \n",
       "518330  ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ Âêç...   \n",
       "518331  ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ Âêç...   \n",
       "...                                                   ...   \n",
       "913331  Ë£úÂä©Ë®òÂè∑ ÂΩ¢Áä∂Ë©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Êé•È†≠Ëæû ÂêçË©û...   \n",
       "913332  ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂãïË©û ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ Âêç...   \n",
       "913333  ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ ÂâØË©û Âä©Ë©û...   \n",
       "913334  ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫...   \n",
       "913335  Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û ...   \n",
       "\n",
       "                                            desc_sentence  \\\n",
       "518327                                                      \n",
       "518328                    ÂêçË©û Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ Á©∫ÁôΩ ÂêçË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û   \n",
       "518329                                      ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û   \n",
       "518330  Ë£úÂä©Ë®òÂè∑ ÂêçË©û Âä©ÂãïË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û Âä©Ë©û ÂãïË©û ÂêçË©û Âä©Ë©û ÂãïË©û ...   \n",
       "518331  Ë£úÂä©Ë®òÂè∑ Êé•È†≠Ëæû ÂêçË©û Âä©Ë©û ÂêçË©û ÂãïË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Âä©ÂãïË©û...   \n",
       "...                                                   ...   \n",
       "913331  ÂΩ¢Áä∂Ë©û ÂêçË©û Âä©Ë©û ÂêçË©û Á©∫ÁôΩ ÂêçË©û Âä©Ë©û ÂêçË©û Âä©Ë©û ÂêçË©û ÂêçË©û Âä©Ë©û Âä©Ë©û Êé•È†≠Ëæû ÂêçË©û...   \n",
       "913332  Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂΩ¢Áä∂Ë©û Ë£úÂä©Ë®òÂè∑ ÂΩ¢Áä∂Ë©û Âä©ÂãïË©û ÂãïË©û Âä©ÂãïË©û Ë£úÂä©Ë®òÂè∑ ÂâØË©û ÂêçË©û ÂãïË©û ...   \n",
       "913333  Ë£úÂä©Ë®òÂè∑ Á©∫ÁôΩ ÂΩ¢Áä∂Ë©û Âä©ÂãïË©û Á©∫ÁôΩ ÂêçË©û ÂêçË©û Á©∫ÁôΩ Ë£úÂä©Ë®òÂè∑ Á©∫ÁôΩ Êé•È†≠Ëæû ÂêçË©û Âä©Ë©û ...   \n",
       "913334  Ë£úÂä©Ë®òÂè∑ Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Êé•Â∞æËæû Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û ÂêçË©û ÂΩ¢Áä∂Ë©û ÂêçË©û ÂêçË©û Âä©Ë©û...   \n",
       "913335  Ë£úÂä©Ë®òÂè∑ ÂêçË©û ÂêçË©û Âä©Ë©û ÂΩ¢Áä∂Ë©û ÂêçË©û ÂêçË©û Âä©Ë©û ÂêçË©û Ë£úÂä©Ë®òÂè∑ ÂΩ¢ÂÆπË©û ÂêçË©û Êé•Â∞æËæû ...   \n",
       "\n",
       "                                               embeddings  \n",
       "518327                                               None  \n",
       "518328  [-0.430854856967926, -0.03222300750868661, -0....  \n",
       "518329  [-0.3310650587081909, 0.09188008668239821, -0....  \n",
       "518330  [-0.6355263629685277, 0.15451034741557162, 0.0...  \n",
       "518331  [-0.6369290975283604, 0.13606688707154624, -0....  \n",
       "...                                                   ...  \n",
       "913331  [-0.5243311790098627, 0.1692050838932754, -0.5...  \n",
       "913332  [-0.3921291038393974, 0.04545600228011608, -0....  \n",
       "913333  [-0.5518289059400558, 0.11609400767419073, -0....  \n",
       "913334  [-0.518697532645443, 0.07392928710109309, -0.1...  \n",
       "913335  [-0.47958834249843924, 0.020226624678791494, -...  \n",
       "\n",
       "[395009 rows x 16 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jp_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "62e638c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty embeddings found.\n"
     ]
    }
   ],
   "source": [
    "empty_embeddings = jp_samples['embeddings'].apply(lambda x: len(x) == 0 if x is not None else True)\n",
    "if empty_embeddings.any():\n",
    "    print(\"Empty embeddings found.\")\n",
    "else:\n",
    "    print(\"No empty embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee22f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with None values in the embeddings column\n",
    "jp_samples.dropna(subset=['embeddings'], inplace=True)\n",
    "uk_samples.dropna(subset=['embeddings'], inplace=True)\n",
    "de_samples.dropna(subset=['embeddings'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc66e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_df = pd.read_csv(\"sessions_test_task1_phase1.csv\")\n",
    "def extract_ids(ids_str):\n",
    "    ids_str = ids_str.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "    return [id_.strip() for id_ in ids_str.split(\" \") if id_.strip() != ' ']\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to each element of the 'prev_items' column and assign the result to a new column 'prev_item_ids'\n",
    "session_df['prev_item_ids'] = session_df['prev_items'].apply(extract_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce242c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e52ecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_sessions = session_df[session_df['locale'] == 'UK'].copy()\n",
    "de_sessions = session_df[session_df['locale'] == 'DE'].copy()\n",
    "jp_sessions = session_df[session_df['locale'] == 'JP'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051e29f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dict = dict(zip(uk_samples['id'], uk_samples['embeddings']))\n",
    "embeddings_dict_DE = dict(zip(de_samples['id'], de_samples['embeddings']))\n",
    "embeddings_dict_JP = dict(zip(de_samples['id'], de_samples['embeddings']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059dbc74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66bfaf5b",
   "metadata": {},
   "source": [
    "UK_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7939a121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'prev_item_ids' is a column in the 'uk_df' DataFrame containing the product IDs of previously purchased items\n",
    "uk_sessions['prev_item_embeddings'] = uk_sessions['prev_item_ids'].apply(lambda ids: [embeddings_dict.get(id) for id in ids if id in embeddings_dict])\n",
    "\n",
    "# Function to calculate the average embedding for a list of embeddings\n",
    "def calculate_average_embedding(embedding_list):\n",
    "    if embedding_list:\n",
    "        return np.mean(embedding_list, axis=0)\n",
    "    return None\n",
    "\n",
    "# Calculate the average embedding for previous items\n",
    "uk_sessions['avg_prev_item_embedding'] = uk_sessions['prev_item_embeddings'].apply(calculate_average_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458e855d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1dd449bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty embeddings found.\n"
     ]
    }
   ],
   "source": [
    "empty_embeddings = uk_sessions['avg_prev_item_embedding'].apply(lambda x: len(x) == 0 if x is not None else True)\n",
    "if empty_embeddings.any():\n",
    "    print(\"Empty embeddings found.\")\n",
    "else:\n",
    "    print(\"No empty embeddings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9ee0ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_sessions.dropna(subset=['avg_prev_item_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3d635",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate cosine similarity between two embeddings\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    if embedding1 is not None and embedding2 is not None:\n",
    "        embedding1 = embedding1.reshape(1, -1)\n",
    "        embedding2 = embedding2.reshape(1, -1)\n",
    "        return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "    return 0.0\n",
    "\n",
    "# Select top 100 products with maximum cosine similarity for each row in uk_df\n",
    "uk_sessions['top_similar_products'] = uk_sessions['avg_prev_item_embedding'].apply(\n",
    "    lambda avg_embedding: sorted(\n",
    "        embeddings_dict.keys(),\n",
    "        key=lambda product_id: calculate_cosine_similarity(avg_embedding, embeddings_dict[product_id]),\n",
    "        reverse=True\n",
    "    )[:100]\n",
    ")\n",
    "\n",
    "uk_sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bee64e8",
   "metadata": {},
   "source": [
    "DE_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104db863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'prev_item_ids' is a column in the 'uk_df' DataFrame containing the product IDs of previously purchased items\n",
    "de_sessions['prev_item_embeddings'] = de_sessions['prev_item_ids'].apply(lambda ids: [embeddings_dict_DE.get(id) for id in ids if id in embeddings_dict_DE])\n",
    "\n",
    "# Function to calculate the average embedding for a list of embeddings\n",
    "def calculate_average_embedding(embedding_list):\n",
    "    if embedding_list:\n",
    "        return np.mean(embedding_list, axis=0)\n",
    "    return None\n",
    "\n",
    "# Calculate the average embedding for previous items\n",
    "de_sessions['avg_prev_item_embedding'] = de_sessions['prev_item_embeddings'].apply(calculate_average_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88650e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "de_sessions.dropna(subset=['avg_prev_item_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b65cc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate cosine similarity between two embeddings\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    if embedding1 is not None and embedding2 is not None:\n",
    "        embedding1 = embedding1.reshape(1, -1)\n",
    "        embedding2 = embedding2.reshape(1, -1)\n",
    "        return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "    return 0.0\n",
    "\n",
    "# Select top 100 products with maximum cosine similarity for each row in uk_df\n",
    "de_sessions['top_similar_products'] = de_sessions['avg_prev_item_embedding'].apply(\n",
    "    lambda avg_embedding: sorted(\n",
    "        embeddings_dict.keys(),\n",
    "        key=lambda product_id: calculate_cosine_similarity(avg_embedding, embeddings_dict_DE[product_id]),\n",
    "        reverse=True\n",
    "    )[:100]\n",
    ")\n",
    "de_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7641ef09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c2b9bd9",
   "metadata": {},
   "source": [
    "JP_SAMPLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'prev_item_ids' is a column in the 'uk_df' DataFrame containing the product IDs of previously purchased items\n",
    "jp_sessions['prev_item_embeddings'] = jp_sessions['prev_item_ids'].apply(lambda ids: [embeddings_dict_JP.get(id) for id in ids if id in embeddings_dict_JP])\n",
    "\n",
    "# Function to calculate the average embedding for a list of embeddings\n",
    "def calculate_average_embedding(embedding_list):\n",
    "    if embedding_list:\n",
    "        return np.mean(embedding_list, axis=0)\n",
    "    return None\n",
    "\n",
    "# Calculate the average embedding for previous items\n",
    "jp_sessions['avg_prev_item_embedding'] = jp_sessions['prev_item_embeddings'].apply(calculate_average_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4483aab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jp_sessions.dropna(subset=['avg_prev_item_embedding'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe158838",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate cosine similarity between two embeddings\n",
    "def calculate_cosine_similarity(embedding1, embedding2):\n",
    "    if embedding1 is not None and embedding2 is not None:\n",
    "        embedding1 = embedding1.reshape(1, -1)\n",
    "        embedding2 = embedding2.reshape(1, -1)\n",
    "        return cosine_similarity(embedding1, embedding2)[0][0]\n",
    "    return 0.0\n",
    "\n",
    "# Select top 100 products with maximum cosine similarity for each row in uk_df\n",
    "jp_sessions['top_similar_products'] = jp_sessions['avg_prev_item_embedding'].apply(\n",
    "    lambda avg_embedding: sorted(\n",
    "        embeddings_dict.keys(),\n",
    "        key=lambda product_id: calculate_cosine_similarity(avg_embedding, embeddings_dict_JP[product_id]),\n",
    "        reverse=True\n",
    "    )[:100]\n",
    ")\n",
    "jp_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133c6b47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
